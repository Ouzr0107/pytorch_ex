{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "04_pytorch_custom_datasets_exercises.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyO06uacGGDzw0TkyZ8mqgSU",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/04_pytorch_custom_datasets_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 04. PyTorch Custom Datasets Exercises Template\n",
    "\n",
    "Welcome to the 04. PyTorch Custom Datasets exercise template.\n",
    "\n",
    "The best way to practice PyTorch code is to write more PyTorch code.\n",
    "\n",
    "So read the original notebook and try to complete the exercises by writing code where it's required.\n",
    "\n",
    "Feel free to reference the original resources whenever you need but should practice writing all of the code yourself.\n",
    "\n",
    "## Resources\n",
    "\n",
    "1. These exercises/solutions are based on [notebook 04 of the Learn PyTorch for Deep Learning course](https://www.learnpytorch.io/04_pytorch_custom_datasets/).\n",
    "2. See a live [walkthrough of the solutions (errors and all) on YouTube](https://youtu.be/vsFMF9wqWx0).\n",
    "3. See [other solutions on the course GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions)."
   ],
   "metadata": {
    "id": "Vex99np2wFVt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Check for GPU\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaeYzOTLwWh2",
    "outputId": "14673108-7705-4e73-b7bc-d94bf9c96423",
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-16T02:53:24.307853Z",
     "start_time": "2025-09-16T02:53:24.218857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 16 10:53:24 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.88                 Driver Version: 580.88         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   56C    P3             30W /  129W |    4228MiB /   6144MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A             260    C+G   ...ram Files\\Tencent\\QQNT\\QQ.exe      N/A      |\n",
      "|    0   N/A  N/A             460    C+G   ....0.3485.66\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A             660    C+G   ...yb3d8bbwe\\Microsoft.Notes.exe      N/A      |\n",
      "|    0   N/A  N/A            2760    C+G   ...dzpwqaze\\app\\Twinkle Tray.exe      N/A      |\n",
      "|    0   N/A  N/A            4640    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            4780    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A            5300    C+G   ...ram Files\\FlClash\\FlClash.exe      N/A      |\n",
      "|    0   N/A  N/A            5688    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A            6932    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A            8408    C+G   ...a\\Roaming\\Spotify\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           10988    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           11620    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           12128    C+G   ...ffice6\\promecefpluginhost.exe      N/A      |\n",
      "|    0   N/A  N/A           13020    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           13564    C+G   ...8bbwe\\Microsoft.CmdPal.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           13648    C+G   ...s\\PowerToys.ColorPickerUI.exe      N/A      |\n",
      "|    0   N/A  N/A           13896    C+G   ...Toys\\PowerToys.FancyZones.exe      N/A      |\n",
      "|    0   N/A  N/A           14168    C+G   ...UI3Apps\\PowerToys.Peek.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           14616    C+G   ...roadcast\\NVIDIA Broadcast.exe      N/A      |\n",
      "|    0   N/A  N/A           18340    C+G   ....0.3485.66\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A           18512    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           20408    C+G   ...acted\\runtime\\WeChatAppEx.exe      N/A      |\n",
      "|    0   N/A  N/A           20892    C+G   ...Telegram Desktop\\Telegram.exe      N/A      |\n",
      "|    0   N/A  N/A           21240    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           22276    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           24044    C+G   ...yCharm\\jbr\\bin\\cef_server.exe      N/A      |\n",
      "|    0   N/A  N/A           24652    C+G   ...\\common\\BongoCat\\BongoCat.exe      N/A      |\n",
      "|    0   N/A  N/A           26028    C+G   ...main\\current_new\\DingTalk.exe      N/A      |\n",
      "|    0   N/A  N/A           29756    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           34228    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           37308    C+G   ...ricify Lite\\Lyricify Lite.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Exercises require PyTorch > 1.10.0\n",
    "print(torch.__version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "DNwZLMbCzJLk",
    "outputId": "1a7b73e2-ec4b-41b0-b4da-c3216a8a29ac",
    "ExecuteTime": {
     "end_time": "2025-09-16T02:54:36.547979Z",
     "start_time": "2025-09-16T02:54:36.526610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Our models are underperforming (not fitting the data well). What are 3 methods for preventing underfitting? Write them down and explain each with a sentence."
   ],
   "metadata": {
    "id": "FSFX7tc1w-en"
   }
  },
  {
   "cell_type": "markdown",
   "source": "添加更多层，调整学习率，增加训练次数",
   "metadata": {
    "id": "-90Qvx9gtrLj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Recreate the data loading functions we built in [sections 1, 2, 3 and 4 of notebook 04](https://www.learnpytorch.io/04_pytorch_custom_datasets/). You should have train and test `DataLoader`'s ready to use."
   ],
   "metadata": {
    "id": "oBK-WI6YxDYa"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Get data\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"tiny_imagenet\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(data_path / \"tiny_imagenet.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\")\n",
    "    print(\"Downloading Tiny ImageNet...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "with zipfile.ZipFile(data_path / \"tiny_imagenet.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping Tiny ImageNet...\")\n",
    "    zip_ref.extractall(image_path)"
   ],
   "metadata": {
    "id": "MZkCPJBR3lw4",
    "ExecuteTime": {
     "end_time": "2025-09-16T03:16:09.198820Z",
     "start_time": "2025-09-16T03:11:28.684269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\tiny_imagenet directory exists.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 16\u001B[39m\n\u001B[32m     13\u001B[39m     image_path.mkdir(parents=\u001B[38;5;28;01mTrue\u001B[39;00m, exist_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(data_path / \u001B[33m\"\u001B[39m\u001B[33mtiny_imagenet.zip\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mwb\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m     request = \u001B[43mrequests\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mhttp://cs231n.stanford.edu/tiny-imagenet-200.zip\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mDownloading Tiny ImageNet...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     18\u001B[39m     f.write(request.content)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001B[39m, in \u001B[36mget\u001B[39m\u001B[34m(url, params, **kwargs)\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mget\u001B[39m(url, params=\u001B[38;5;28;01mNone\u001B[39;00m, **kwargs):\n\u001B[32m     63\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33mr\u001B[39m\u001B[33;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[32m     64\u001B[39m \n\u001B[32m     65\u001B[39m \u001B[33;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     70\u001B[39m \u001B[33;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[32m     71\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mget\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001B[39m, in \u001B[36mrequest\u001B[39m\u001B[34m(method, url, **kwargs)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[32m     57\u001B[39m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m sessions.Session() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m=\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001B[39m, in \u001B[36mSession.request\u001B[39m\u001B[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[39m\n\u001B[32m    584\u001B[39m send_kwargs = {\n\u001B[32m    585\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mtimeout\u001B[39m\u001B[33m\"\u001B[39m: timeout,\n\u001B[32m    586\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mallow_redirects\u001B[39m\u001B[33m\"\u001B[39m: allow_redirects,\n\u001B[32m    587\u001B[39m }\n\u001B[32m    588\u001B[39m send_kwargs.update(settings)\n\u001B[32m--> \u001B[39m\u001B[32m589\u001B[39m resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    591\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\sessions.py:724\u001B[39m, in \u001B[36mSession.send\u001B[39m\u001B[34m(self, request, **kwargs)\u001B[39m\n\u001B[32m    721\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m allow_redirects:\n\u001B[32m    722\u001B[39m     \u001B[38;5;66;03m# Redirect resolving generator.\u001B[39;00m\n\u001B[32m    723\u001B[39m     gen = \u001B[38;5;28mself\u001B[39m.resolve_redirects(r, request, **kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m724\u001B[39m     history = \u001B[43m[\u001B[49m\u001B[43mresp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mresp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgen\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    726\u001B[39m     history = []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\sessions.py:265\u001B[39m, in \u001B[36mSessionRedirectMixin.resolve_redirects\u001B[39m\u001B[34m(self, resp, req, stream, timeout, verify, cert, proxies, yield_requests, **adapter_kwargs)\u001B[39m\n\u001B[32m    263\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m req\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m265\u001B[39m     resp = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    266\u001B[39m \u001B[43m        \u001B[49m\u001B[43mreq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    267\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    268\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    269\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverify\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverify\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    270\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcert\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcert\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    271\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    272\u001B[39m \u001B[43m        \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    273\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43madapter_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    274\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    276\u001B[39m     extract_cookies_to_jar(\u001B[38;5;28mself\u001B[39m.cookies, prepared_request, resp.raw)\n\u001B[32m    278\u001B[39m     \u001B[38;5;66;03m# extract redirect url, if any, for the next loop\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\sessions.py:746\u001B[39m, in \u001B[36mSession.send\u001B[39m\u001B[34m(self, request, **kwargs)\u001B[39m\n\u001B[32m    743\u001B[39m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[32m    745\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[32m--> \u001B[39m\u001B[32m746\u001B[39m     \u001B[43mr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcontent\u001B[49m\n\u001B[32m    748\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\models.py:902\u001B[39m, in \u001B[36mResponse.content\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    900\u001B[39m         \u001B[38;5;28mself\u001B[39m._content = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    901\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m902\u001B[39m         \u001B[38;5;28mself\u001B[39m._content = \u001B[33;43mb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    904\u001B[39m \u001B[38;5;28mself\u001B[39m._content_consumed = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    905\u001B[39m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[32m    906\u001B[39m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001B[39m, in \u001B[36mResponse.iter_content.<locals>.generate\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    818\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.raw, \u001B[33m\"\u001B[39m\u001B[33mstream\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    819\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m820\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m.raw.stream(chunk_size, decode_content=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    821\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    822\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\urllib3\\response.py:1091\u001B[39m, in \u001B[36mHTTPResponse.stream\u001B[39m\u001B[34m(self, amt, decode_content)\u001B[39m\n\u001B[32m   1089\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1090\u001B[39m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m._fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) > \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1091\u001B[39m         data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1093\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[32m   1094\u001B[39m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\urllib3\\response.py:980\u001B[39m, in \u001B[36mHTTPResponse.read\u001B[39m\u001B[34m(self, amt, decode_content, cache_content)\u001B[39m\n\u001B[32m    977\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) >= amt:\n\u001B[32m    978\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._decoded_buffer.get(amt)\n\u001B[32m--> \u001B[39m\u001B[32m980\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    982\u001B[39m flush_decoder = amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt != \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[32m    984\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._decoded_buffer) == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\urllib3\\response.py:904\u001B[39m, in \u001B[36mHTTPResponse._raw_read\u001B[39m\u001B[34m(self, amt, read1)\u001B[39m\n\u001B[32m    901\u001B[39m fp_closed = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m._fp, \u001B[33m\"\u001B[39m\u001B[33mclosed\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    903\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._error_catcher():\n\u001B[32m--> \u001B[39m\u001B[32m904\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread1\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[33mb\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    905\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt != \u001B[32m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[32m    906\u001B[39m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[32m    907\u001B[39m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    912\u001B[39m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[32m    913\u001B[39m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[32m    914\u001B[39m         \u001B[38;5;28mself\u001B[39m._fp.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\pytorch_ex\\.venv\\Lib\\site-packages\\urllib3\\response.py:887\u001B[39m, in \u001B[36mHTTPResponse._fp_read\u001B[39m\u001B[34m(self, amt, read1)\u001B[39m\n\u001B[32m    884\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read1()\n\u001B[32m    885\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    886\u001B[39m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m887\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m._fp.read()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:479\u001B[39m, in \u001B[36mHTTPResponse.read\u001B[39m\u001B[34m(self, amt)\u001B[39m\n\u001B[32m    476\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.length \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt > \u001B[38;5;28mself\u001B[39m.length:\n\u001B[32m    477\u001B[39m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[32m    478\u001B[39m     amt = \u001B[38;5;28mself\u001B[39m.length\n\u001B[32m--> \u001B[39m\u001B[32m479\u001B[39m s = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[32m    481\u001B[39m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[32m    482\u001B[39m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[32m    483\u001B[39m     \u001B[38;5;28mself\u001B[39m._close_conn()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001B[39m, in \u001B[36mSocketIO.readinto\u001B[39m\u001B[34m(self, b)\u001B[39m\n\u001B[32m    717\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mcannot read from timed out object\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    718\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m719\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sock\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    720\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[32m    721\u001B[39m     \u001B[38;5;28mself\u001B[39m._timeout_occurred = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001B[39m, in \u001B[36mSSLSocket.recv_into\u001B[39m\u001B[34m(self, buffer, nbytes, flags)\u001B[39m\n\u001B[32m   1300\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m flags != \u001B[32m0\u001B[39m:\n\u001B[32m   1301\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1302\u001B[39m           \u001B[33m\"\u001B[39m\u001B[33mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[33m\"\u001B[39m %\n\u001B[32m   1303\u001B[39m           \u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1304\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1305\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1306\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001B[39m, in \u001B[36mSSLSocket.read\u001B[39m\u001B[34m(self, len, buffer)\u001B[39m\n\u001B[32m   1136\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m   1137\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1138\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sslobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1139\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1140\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sslobj.read(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# 2. Become one with the data\n",
    "import os\n",
    "\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"Walks through dir_path returning file counts of its contents.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_dir(image_path)"
   ],
   "metadata": {
    "id": "TYmhAX7J52VX"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Setup train and testing paths\n"
   ],
   "metadata": {
    "id": "3A9ZmOn-7Jhh"
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Visualize an image"
   ],
   "metadata": {
    "id": "51ywNKkN7WOl"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Do the image visualization with matplotlib\n"
   ],
   "metadata": {
    "id": "Qe4LoASC9sQ-"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We've got some images in our folders.\n",
    "\n",
    "Now we need to make them compatible with PyTorch by:\n",
    "1. Transform the data into tensors.\n",
    "2. Turn the tensor data into a `torch.utils.data.Dataset` and later a `torch.utils.data.DataLoader`."
   ],
   "metadata": {
    "id": "2AU4FGYC_KBz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# 3.1 Transforming data with torchvision.transforms\n"
   ],
   "metadata": {
    "id": "KbGMaYGT-vwq"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Write transform for turning images into tensors\n"
   ],
   "metadata": {
    "id": "gnvUSYYW_ohN"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Write a function to plot transformed images\n"
   ],
   "metadata": {
    "id": "vp8I2cpMAxcT"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load image data using `ImageFolder`"
   ],
   "metadata": {
    "id": "FKgfqPArChVR"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use ImageFolder to create dataset(s)\n"
   ],
   "metadata": {
    "id": "8OFgwQF1CkOu"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbT0fhXHEQyJ",
    "outputId": "ad2b0da9-285c-493d-c362-a6b00e5d2197"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCcWk7NDEay1",
    "outputId": "88718fd6-c6b2-4132-9383-0a64a0a7bcee"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Check the lengths of each dataset\n",
    "len(train_data), len(test_data)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7H7bX4HEgie",
    "outputId": "2ff1fdd2-f990-461d-c2e9-27435e7744c9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(225, 75)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Turn train and test Datasets into DataLoaders\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nskNr5YCEoRl",
    "outputId": "cd825b1d-095f-4080-86ce-7d17aafef7e8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fce57ec08d0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fce57ec0dd0>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# How many batches of images are in our data loaders?\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z8vJxmxAFqw6",
    "outputId": "e5a8bd88-1b05-4109-de5a-8183a85c7872"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(225, 75)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Recreate `model_0` we built in section 7 of notebook 04."
   ],
   "metadata": {
    "id": "XeYFEqw8xK26"
   }
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "MBErjcUCyDzE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Create training and testing functions for `model_0`."
   ],
   "metadata": {
    "id": "DKdEEFEqxM-8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put the model in train mode\n",
    "    model.train()\n",
    "\n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    # Loop through data loader and data batches\n",
    "\n",
    "    # Send data to target device\n",
    "\n",
    "    # 1. Forward pass\n",
    "\n",
    "    # 2. Calculate and accumulate loss\n",
    "\n",
    "    # 3. Optimizer zero grad \n",
    "\n",
    "    # 4. Loss backward \n",
    "\n",
    "    # 5. Optimizer step\n",
    "\n",
    "    # Calculate and accumualte accuracy metric across all batches\n",
    "\n",
    "    # Adjust metrics to get average loss and average accuracy per batch\n"
   ],
   "metadata": {
    "id": "rnUox1qayDes"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval()\n",
    "\n",
    "    # Setup the test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    # Turn on inference context manager\n",
    "\n",
    "    # Loop through DataLoader batches\n",
    "\n",
    "    # Send data to target device\n",
    "\n",
    "    # 1. Forward pass\n",
    "\n",
    "    # 2. Calculuate and accumulate loss\n",
    "\n",
    "    # Calculate and accumulate accuracy\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch\n"
   ],
   "metadata": {
    "id": "O7_EVPpHNKUP"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    # Create results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"test_acc\": []}\n",
    "\n",
    "    # Loop through the training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train step\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        # Test step\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                        dataloader=test_dataloader,\n",
    "                                        loss_fn=loss_fn)\n",
    "\n",
    "        # Print out what's happening\n",
    "        print(f\"Epoch: {epoch + 1} | \"\n",
    "              f\"train_loss: {train_loss:.4f} | \"\n",
    "              f\"train_acc: {train_acc:.4f} | \"\n",
    "              f\"test_loss: {test_loss:.4f} | \"\n",
    "              f\"test_acc: {test_acc:.4f}\"\n",
    "              )\n",
    "\n",
    "        # Update the results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # Return the results dictionary\n",
    "    return results"
   ],
   "metadata": {
    "id": "zXxTIh9tOh68"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Try training the model you made in exercise 3 for 5, 20 and 50 epochs, what happens to the results?\n",
    "* Use `torch.optim.Adam()` with a learning rate of 0.001 as the optimizer. "
   ],
   "metadata": {
    "id": "lvf-3pODxXYI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Train for 5 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(  #TODO,\n",
    "    lr=0.001)"
   ],
   "metadata": {
    "id": "rV7s2qtIyDIZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train for 20 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(  #TODO,\n",
    "    lr=0.001)"
   ],
   "metadata": {
    "id": "UEtZzyF1QGTq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train for 50 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(  #TODO,\n",
    "    lr=0.001)"
   ],
   "metadata": {
    "id": "Dwvg40qAQGP9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like our model is starting to overfit towards the end (performing far better on the training data than on the testing data).\n",
    "\n",
    "In order to fix this, we'd have to introduce ways of preventing overfitting."
   ],
   "metadata": {
    "id": "fn8_fDGzQGMn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Double the number of hidden units in your model and train it for 20 epochs, what happens to the results?"
   ],
   "metadata": {
    "id": "qxZW-uAbxe_F"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Double the number of hidden units and train for 20 epochs\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n"
   ],
   "metadata": {
    "id": "HdRM86voyC0x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like the model is still overfitting, even when changing the number of hidden units.\n",
    "\n",
    "To fix this, we'd have to look at ways to prevent overfitting with our model."
   ],
   "metadata": {
    "id": "THYGHbxyTfzM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Double the data you're using with your model from step 6 and train it for 20 epochs, what happens to the results?\n",
    "* **Note:** You can use the [custom data creation notebook](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/04_custom_data_creation.ipynb) to scale up your Food101 dataset.\n",
    "* You can also find the [already formatted double data (20% instead of 10% subset) dataset on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/data/pizza_steak_sushi_20_percent.zip), you will need to write download code like in exercise 2 to get it into this notebook."
   ],
   "metadata": {
    "id": "JAPDzW0wxhi3"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Download 20% data for Pizza/Steak/Sushi from GitHub\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download pizza, steak, sushi data\n",
    "with open(data_path / \"pizza_steak_sushi_20_percent.zip\", \"wb\") as f:\n",
    "    request = requests.get(\n",
    "        \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
    "    print(\"Downloading pizza, steak, sushi 20% data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "# Unzip pizza, steak, sushi data\n",
    "with zipfile.ZipFile(data_path / \"pizza_steak_sushi_20_percent.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak, sushi 20% data...\")\n",
    "    zip_ref.extractall(image_path)"
   ],
   "metadata": {
    "id": "8tWfa7Y0yCkX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# See how many images we have\n",
    "walk_through_dir(image_path)"
   ],
   "metadata": {
    "id": "DrFK2ScnVg4q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Excellent, we now have double the training and testing images... "
   ],
   "metadata": {
    "id": "WhlWd-z-Vk22"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the train and test paths\n",
    "train_data_20_percent_path = image_path / \"train\"\n",
    "test_data_20_percent_path = image_path / \"test\"\n",
    "\n",
    "train_data_20_percent_path, test_data_20_percent_path"
   ],
   "metadata": {
    "id": "hNzXRfO1Tt1Q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Turn the 20 percent datapaths into Datasets and DataLoaders\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "\n",
    "\n",
    "# Create dataloaders\n"
   ],
   "metadata": {
    "id": "R1_xU3FQUPkN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train a model with increased amount of data\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ],
   "metadata": {
    "id": "BuJ9YpRCVXRm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Make a prediction on your own custom image of pizza/steak/sushi (you could even download one from the internet) with your trained model from exercise 7 and share your prediction. \n",
    "* Does the model you trained in exercise 7 get it right? \n",
    "* If not, what do you think you could do to improve it?"
   ],
   "metadata": {
    "id": "bCCVfXk5xjYS"
   }
  },
  {
   "cell_type": "code",
   "source": [
    ""
   ],
   "metadata": {
    "id": "Q1X-33t0vT20"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
